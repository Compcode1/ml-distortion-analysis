{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction and Project Outline**\n",
    "\n",
    "### **Introduction**\n",
    "The goal of this project is to test the robustness of an already established XGBoost model ([xgboost_model.pkl](https://github.com/Compcode1/ml-predictions-exam-scores/blob/main/xgboost_model.pkl)), which was previously trained on a dataset of 250,000 rows containing various medical diagnoses and lifestyle factors to predict exam scores ([medrecords.csv](https://github.com/Compcode1/ml-predictions-exam-scores/blob/main/medrecords.csv)). \n",
    "\n",
    "The XGBoost model demonstrated impressive performance on the original dataset, with high R-squared values and low Mean Squared Error (MSE). Here are some of the key performance metrics from the original project:\n",
    "\n",
    "- **XGBoost Model MSE**: 0.02338906874154974\n",
    "- **XGBoost Model R-squared**: 0.9999245421116839\n",
    "- **Cross-Validated MSE for each fold**: [0.02500604, 0.01728912, 0.01483328, 0.02271097, 0.02217558]\n",
    "- **Mean Cross-Validated MSE**: 0.02040299750467838\n",
    "- **Standard Deviation of MSE**: 0.003751659821773931\n",
    "- **Original Exam Scores for the first 5 rows**: [ 81.  72. 110.  77.  77.]\n",
    "- **Predicted Exam Scores for the first 5 rows**: [ 80.987045, 72.02215, 109.99814, 77.011765, 77.01987]\n",
    "- **MSE for the first 5 rows**: 0.00023898585932329296\n",
    "- **Original Exam Scores for the first 1,000 rows**: [ 81., 72., 110., 77., 77., 85.5, 26.136837, 58.905, 47.5657875, 87.]\n",
    "- **Predicted Exam Scores for the first 1,000 rows**: [ 80.987045, 72.02215, 109.99814, 77.011765, 77.01987, 85.495255, 26.2142, 59.47049, 47.51045, 86.996826]\n",
    "- **MSE for the first 1,000 rows**: 0.010526539734485856\n",
    "- **MSE for the entire dataset**: 0.016013743906791843\n",
    "\n",
    "In this extension of the project, we introduce a new target variable, **Exam Score 2**, based on an arbitrary formula derived from the row index. This new variable is expected to have no significant correlation with the original features. The aim is to observe how the same XGBoost model performs when the target variable is unrelated to the input features, testing the model's generalization and performance under challenging conditions.\n",
    "\n",
    "My hypothesis is that the model will struggle to make accurate predictions for **Exam Score 2**, given that the new target has little to no alignment with the input features.\n",
    "\n",
    "---\n",
    "\n",
    "### **Project Outline**\n",
    "\n",
    "#### **Step 1: Setting up the Environment**\n",
    "- Load the dataset (`medrecords.csv`) into a Pandas DataFrame.\n",
    "- Verify the dataset is clean, with no missing or corrupted values.\n",
    "- Import the necessary libraries (e.g., pandas, numpy, xgboost, and sklearn).\n",
    "\n",
    "#### **Step 2: Add a New Target Column (Exam Score 2)**\n",
    "- Define a function that generates the **Exam Score 2** value based on the last digit of the row index.\n",
    "- Apply this function across all rows to create the new column.\n",
    "\n",
    "#### **Step 3: Preprocessing the Data**\n",
    "- One-hot encode categorical variables (e.g., Gender).\n",
    "- Standardize numerical features such as Age and BMI.\n",
    "- Drop unnecessary or redundant columns such as Exam Age and Age Group.\n",
    "\n",
    "#### **Step 4: Split the Dataset**\n",
    "- Split the dataset into training and testing sets (e.g., 80/20 split).\n",
    "- Ensure **Exam Score 2** is the target variable in this iteration.\n",
    "\n",
    "#### **Step 5: Train the XGBoost Model on Exam Score 2**\n",
    "- Load the saved XGBoost model (optional: retrain if needed).\n",
    "- Train the model on the new dataset with **Exam Score 2** as the target.\n",
    "- Evaluate the model using the same performance metrics: Mean Squared Error (MSE), R-squared, and cross-validation results.\n",
    "\n",
    "#### **Step 6: Evaluate Model Performance**\n",
    "- Compare the modelâ€™s performance on **Exam Score 2** with the performance metrics from the original **Exam Score**.\n",
    "- Analyze the results: Does the model struggle with the new, arbitrary target variable? Are the metrics significantly worse?\n",
    "\n",
    "#### **Step 7: Document Findings**\n",
    "- Summarize the findings in terms of model generalization and feature importance.\n",
    "- Discuss whether the model can generalize well with an unrelated target variable, and the implications for using machine learning models on structured data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Age Age Group   BMI  Obesity  Smoking  High Alcohol  Heart Disease  \\\n",
      "0    Male   27     18-44  22.7        0        0             0              0   \n",
      "1  Female   54     45-64  28.5        0        0             0              0   \n",
      "2    Male   21     18-44  21.3        0        0             1              0   \n",
      "3  Female   62     45-64  28.6        0        0             0              0   \n",
      "4    Male   61     45-64  21.4        0        0             1              0   \n",
      "\n",
      "   Cancer  COPD  Alzheimers  Diabetes  CKD  High Blood Pressure  Stroke  \\\n",
      "0       0     0           0         0    0                    0       0   \n",
      "1       0     0           0         1    0                    0       0   \n",
      "2       0     0           0         0    0                    0       0   \n",
      "3       0     0           0         0    0                    0       0   \n",
      "4       0     0           0         0    0                    0       0   \n",
      "\n",
      "   Liver Dx  Strength Exam Age  Exam Score  \n",
      "0         1         0    18-29        81.0  \n",
      "1         0         0    50-59        72.0  \n",
      "2         0         1    18-29       110.0  \n",
      "3         0         0    60-69        77.0  \n",
      "4         0         0    60-69        77.0  \n",
      "\n",
      "Missing values in each column:\n",
      "Gender                 0\n",
      "Age                    0\n",
      "Age Group              0\n",
      "BMI                    0\n",
      "Obesity                0\n",
      "Smoking                0\n",
      "High Alcohol           0\n",
      "Heart Disease          0\n",
      "Cancer                 0\n",
      "COPD                   0\n",
      "Alzheimers             0\n",
      "Diabetes               0\n",
      "CKD                    0\n",
      "High Blood Pressure    0\n",
      "Stroke                 0\n",
      "Liver Dx               0\n",
      "Strength               0\n",
      "Exam Age               0\n",
      "Exam Score             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setting up the Environment\n",
    "\n",
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset from your Desktop\n",
    "file_path = '/Users/steventuschman/Desktop/medrecords.csv'  # Adjust the file path if necessary\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Verify the dataset is clean (check for missing or corrupted values)\n",
    "print(df.head())\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Optional: handle any missing values if necessary\n",
    "# df = df.dropna()  # Uncomment this if you want to drop rows with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Exam Score  Exam Score 2\n",
      "0        81.0            59\n",
      "1        72.0            41\n",
      "2       110.0            73\n",
      "3        77.0            26\n",
      "4        77.0            25\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Step 2: Add a New Target Column (Exam Score 2)\n",
    "\n",
    "# Define a function to generate Exam Score 2 based on the last digit of the index\n",
    "def generate_exam_score_2(index):\n",
    "    last_digit = index % 10  # Get the last digit of the index\n",
    "    \n",
    "    # Assign a random value based on the last digit of the index\n",
    "    if last_digit == 0:\n",
    "        return random.randint(40, 60)\n",
    "    elif last_digit == 1:\n",
    "        return random.randint(30, 50)\n",
    "    elif last_digit == 2:\n",
    "        return random.randint(30, 90)\n",
    "    elif last_digit == 3:\n",
    "        return random.randint(10, 80)\n",
    "    elif last_digit == 4:\n",
    "        return random.randint(20, 30)\n",
    "    elif last_digit == 5:\n",
    "        return random.randint(80, 90)\n",
    "    elif last_digit == 6:\n",
    "        return random.randint(50, 75)\n",
    "    elif last_digit == 7:\n",
    "        return random.randint(10, 90)\n",
    "    elif last_digit == 8:\n",
    "        return random.randint(30, 40)\n",
    "    elif last_digit == 9:\n",
    "        return random.randint(70, 84)\n",
    "\n",
    "# Apply this function to each row to create the new Exam Score 2 column\n",
    "df['Exam Score 2'] = df.index.map(generate_exam_score_2)\n",
    "\n",
    "# Display the updated DataFrame to verify the new column\n",
    "print(df[['Exam Score', 'Exam Score 2']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age       BMI  Obesity  Smoking  High Alcohol  Heart Disease  Cancer  \\\n",
      "0 -1.116721 -0.971258        0        0             0              0       0   \n",
      "1  0.318498 -0.164576        0        0             0              0       0   \n",
      "2 -1.435659 -1.165975        0        0             1              0       0   \n",
      "3  0.743748 -0.150668        0        0             0              0       0   \n",
      "4  0.690592 -1.152066        0        0             1              0       0   \n",
      "\n",
      "   COPD  Alzheimers  Diabetes  CKD  High Blood Pressure  Stroke  Liver Dx  \\\n",
      "0     0           0         0    0                    0       0         1   \n",
      "1     0           0         1    0                    0       0         0   \n",
      "2     0           0         0    0                    0       0         0   \n",
      "3     0           0         0    0                    0       0         0   \n",
      "4     0           0         0    0                    0       0         0   \n",
      "\n",
      "   Strength  Exam Score  Exam Score 2  Gender_Male  \n",
      "0         0        81.0            59         True  \n",
      "1         0        72.0            41        False  \n",
      "2         1       110.0            73         True  \n",
      "3         0        77.0            26        False  \n",
      "4         0        77.0            25         True  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Step 3: Preprocessing the Data\n",
    "\n",
    "# One-hot encode categorical variables (Gender)\n",
    "df_encoded = pd.get_dummies(df, columns=['Gender'], drop_first=True)\n",
    "\n",
    "# Drop unnecessary columns such as 'Exam Age' and 'Age Group'\n",
    "df_encoded = df_encoded.drop(['Exam Age', 'Age Group'], axis=1)\n",
    "\n",
    "# Standardize numerical features like 'Age' and 'BMI'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Columns to be standardized\n",
    "columns_to_standardize = ['Age', 'BMI']\n",
    "\n",
    "# Apply the standard scaler to the selected columns\n",
    "df_encoded[columns_to_standardize] = scaler.fit_transform(df_encoded[columns_to_standardize])\n",
    "\n",
    "# Display the first few rows of the preprocessed data to verify\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: X_train = (200000, 16), y_train = (200000,)\n",
      "Testing set shape: X_test = (50000, 16), y_test = (50000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 4: Split the Dataset\n",
    "\n",
    "# Define the features (X) and the target variable (y) - Exam Score 2 in this case\n",
    "X = df_encoded.drop(columns=['Exam Score', 'Exam Score 2'])\n",
    "y = df_encoded['Exam Score 2']\n",
    "\n",
    "# Perform an 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(f\"Training set shape: X_train = {X_train.shape}, y_train = {y_train.shape}\")\n",
    "print(f\"Testing set shape: X_test = {X_test.shape}, y_test = {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation on Exam Score 2:\n",
      "Mean Squared Error (MSE): 457.16622435908454\n",
      "R-squared: -0.010028362274169922\n",
      "Cross-Validated MSE for each fold: [-461.5811903  -459.19734528 -458.24252344 -464.60684403 -462.86848149]\n",
      "Mean Cross-Validated MSE: 461.2992769069315\n",
      "Standard Deviation of MSE: 2.33425520545703\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Step 5: Train the XGBoost Model on Exam Score 2\n",
    "\n",
    "# Load the saved XGBoost model (xgboost_model.pkl) if retraining is not required\n",
    "model_path = '/Users/steventuschman/Desktop/xgboost_model.pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    xgboost_model = pickle.load(file)\n",
    "\n",
    "# Alternatively, if retraining is needed, initialize a new XGBoost model\n",
    "# Uncomment the following line if retraining is necessary:\n",
    "# xgboost_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "\n",
    "# Train the XGBoost model on the training set\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE) and R-squared\n",
    "y_pred = xgboost_model.predict(X_test)\n",
    "\n",
    "# Calculate the metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgboost_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "mean_cv_mse = -cv_scores.mean()\n",
    "std_cv_mse = cv_scores.std()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Model Evaluation on Exam Score 2:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Cross-Validated MSE for each fold: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validated MSE: {mean_cv_mse}\")\n",
    "print(f\"Standard Deviation of MSE: {std_cv_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6: Evaluate Model Performance**\n",
    "\n",
    "We compared the model's performance on **Exam Score 2** (an arbitrary target) with its performance on the original **Exam Score** (which had meaningful relationships with the features). Below are the results:\n",
    "\n",
    "**Original Exam Score Performance:**\n",
    "- Mean Squared Error (MSE): **0.0234**\n",
    "- R-squared: **0.9999**\n",
    "- Cross-Validated MSE for each fold: **[0.0250, 0.0173, 0.0148, 0.0227, 0.0222]**\n",
    "- Mean Cross-Validated MSE: **0.0204**\n",
    "- Standard Deviation of MSE: **0.0038**\n",
    "\n",
    "**Exam Score 2 Performance:**\n",
    "- Mean Squared Error (MSE): **458.09**\n",
    "- R-squared: **-0.0107**\n",
    "- Cross-Validated MSE for each fold: **[-463.03, -458.21, -460.63, -460.91, -461.42]**\n",
    "- Mean Cross-Validated MSE: **460.84**\n",
    "- Standard Deviation of MSE: **1.5565**\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "- **Mean Squared Error (MSE)**:\n",
    "  The MSE on **Exam Score 2** is **458.09**, which is substantially worse than the MSE on the original **Exam Score** (0.0234). This large difference indicates that the model is unable to predict **Exam Score 2** accurately due to its arbitrary nature and lack of correlation with the features. \n",
    "\n",
    "- **R-squared**:\n",
    "  The R-squared value for **Exam Score 2** is **-0.0107**, indicating that the model is performing worse than a simple mean prediction, meaning it cannot explain any variance in the target. This is a stark contrast to the near-perfect R-squared of **0.9999** achieved with the original **Exam Score**, where the model was able to capture almost all the variability.\n",
    "\n",
    "- **Cross-Validation MSE**:\n",
    "  For **Exam Score 2**, the cross-validated MSE values are consistently poor across all folds, with an average MSE of **460.84** and a low standard deviation (**1.5565**), showing that the model consistently struggles across different data splits. This is much worse than the mean cross-validated MSE of **0.0204** on the original **Exam Score**, further highlighting the model's inability to generalize to this new target variable.\n",
    "\n",
    "\n",
    "The comparison shows that the model struggles significantly with the arbitrary target variable **Exam Score 2**. The original model had strong performance on the **Exam Score** variable, with very low MSE and high R-squared values. However, when presented with a target variable that has no meaningful relationship with the features, the model's performance declines sharply, as indicated by the extremely high MSE and negative R-squared values for **Exam Score 2**. This demonstrates the importance of having a meaningful correlation between the features and the target variable in machine learning models like XGBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7: Document Findings**\n",
    "\n",
    "### Summary of Findings:\n",
    "\n",
    "Through this experiment, we aimed to test the robustness and generalization of a previously trained XGBoost model by introducing a new, arbitrary target variable (**Exam Score 2**) that had no significant correlation with the input features. The model, which previously demonstrated impressive performance on the original **Exam Score**, showed a dramatic decline in predictive ability when tested on **Exam Score 2**.\n",
    "\n",
    "1. **Model Performance:**\n",
    "   - The XGBoost model performed exceptionally well on the original **Exam Score**, with very low **Mean Squared Error (MSE)** and near-perfect **R-squared** values, indicating a strong ability to capture the relationships between features and the target variable.\n",
    "   - However, when predicting **Exam Score 2**, the model's performance metrics (MSE: **458.09**, R-squared: **-0.0107**) demonstrated that it struggled to make accurate predictions due to the lack of meaningful relationships between the input features and the target variable.\n",
    "\n",
    "2. **Generalization Ability:**\n",
    "   - The significant performance drop on **Exam Score 2** highlights that the XGBoost model cannot generalize well when the target variable has no inherent connection to the input data. The model relies heavily on finding patterns and relationships in structured data, and when those patterns are absent, its predictive power diminishes substantially.\n",
    "   - This demonstrates that machine learning models like XGBoost are designed to optimize for patterns and correlations within the data. Without meaningful features, the model becomes ineffective.\n",
    "\n",
    "3. **Feature Importance:**\n",
    "   - In the original experiment, key features such as **Strength**, **Heart Disease**, **Alzheimer's**, and **Cancer** were identified as important in predicting **Exam Score**. These features had significant correlations with the target variable, enabling the model to perform well.\n",
    "   - In contrast, for **Exam Score 2**, which is arbitrarily assigned, feature importance becomes irrelevant, as the target does not depend on any features. This explains why the model struggles with this unrelated target.\n",
    "\n",
    "### Implications:\n",
    "\n",
    "The results of this experiment underscore the importance of aligning target variables with meaningful features when using machine learning models. If the target variable does not have a logical relationship with the input features, even highly optimized models like XGBoost will fail to produce accurate predictions. This experiment also illustrates the limitations of machine learning when applied to datasets with poorly defined or arbitrary target variables, emphasizing the need for careful feature selection and target definition in predictive modeling tasks.\n",
    "\n",
    "In structured data, models like XGBoost excel at identifying relationships and leveraging feature importance to make accurate predictions. However, the model's inability to perform well on **Exam Score 2** reinforces the importance of understanding the data context and ensuring that the target variable is appropriately aligned with the available features for meaningful model training and evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
